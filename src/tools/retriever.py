import logging
import math
from langchain_openai import OpenAIEmbeddings
from src.config import settings
from src.rag_system.retriever_factory import CohereRerank  # may be None
from src.rag_system.retriever_factory import create_advanced_retriever, get_rag_chain
from src.config import settings



def _get_docs(retriever, question: str):
    try:
        if hasattr(retriever, "invoke"):
            return retriever.invoke(question)
        return retriever.get_relevant_documents(question)
    except Exception:
        return []


def query_dbir_report(query: str) -> str:
    """
    Performs a query to the advanced RAG system and returns the response generated by the hierarchical pipeline.
    """
    try:
        rag_chain = get_rag_chain()
        result = rag_chain.invoke(query)
        return result if result else "No relevant results found in the DBIR report for this query."
    except Exception as e:
        logging.error(f"Error during the query to the advanced RAG system: {e}")
        return "An error occurred while trying to retrieve information from the DBIR report."


async def ask_rag(question: str) -> dict:
    """
    Ejecuta una consulta directa al RAG devolviendo la respuesta y un preview del contexto.
    """
    try:
        retriever = create_advanced_retriever(
            chroma_path=settings.CHROMA_DB_PATH,
            collection_name=settings.COLLECTION_NAME,
            openai_api_key=settings.OPENAI_API_KEY,
            cohere_api_key=getattr(settings, "COHERE_API_KEY", None),
        )
        # Recuperar docs con compatibilidad moderna
        docs = _get_docs(retriever, question)

        # Turbo: sin Cohere y sin MMR; Heavy: MMR si no hay Cohere
        if not settings.is_turbo and docs:
            use_cohere = bool(getattr(settings, "COHERE_API_KEY", None)) and CohereRerank is not None
            if not use_cohere:
                emb = OpenAIEmbeddings(model="text-embedding-3-small", api_key=settings.OPENAI_API_KEY)
                def cosine(a, b):
                    dot = sum(x*y for x, y in zip(a, b))
                    na = math.sqrt(sum(x*x for x in a))
                    nb = math.sqrt(sum(y*y for y in b))
                    return dot / (na * nb + 1e-10)
                q = emb.embed_query(question)
                docs = list(docs)[:20]
                D = [emb.embed_query(getattr(d, 'page_content', str(d))[:2000]) for d in docs]
                sims_q = [cosine(q, d) for d in D]
                selected_idx = []
                first = max(range(len(docs)), key=lambda i: sims_q[i])
                selected_idx.append(first)
                while len(selected_idx) < min(5, len(docs)):
                    best_i = None; best_score = -1e9
                    for i in range(len(docs)):
                        if i in selected_idx:
                            continue
                        max_sim_to_S = max(cosine(D[i], D[j]) for j in selected_idx) if selected_idx else 0.0
                        score = 0.5 * sims_q[i] - 0.5 * max_sim_to_S
                        if score > best_score:
                            best_score = score; best_i = i
                    if best_i is None:
                        break
                    selected_idx.append(best_i)
                docs = [docs[i] for i in selected_idx]

        context = "\n---\n".join(getattr(d, 'page_content', str(d)) for d in docs[:5])
        chain = get_rag_chain()
        answer = chain.invoke(question)
        return {"answer": answer, "context": context}
    except Exception as e:
        logging.error(f"Error in ask_rag: {e}")
        return {"answer": "", "context": ""}


async def get_docs_with_scores(question: str) -> list[dict]:
    """
    Devuelve documentos relevantes con su similitud a la pregunta y si fueron seleccionados por MMR.
    Respuesta: [{"score": float, "selected": bool, "text_preview": str}]
    """
    results: list[dict] = []
    try:
        retriever = create_advanced_retriever(
            chroma_path=settings.CHROMA_DB_PATH,
            collection_name=settings.COLLECTION_NAME,
            openai_api_key=settings.OPENAI_API_KEY,
            cohere_api_key=getattr(settings, "COHERE_API_KEY", None),
        )
        docs = _get_docs(retriever, question)
        emb = OpenAIEmbeddings(model="text-embedding-3-small", api_key=settings.OPENAI_API_KEY)
        q = emb.embed_query(question)
        def cosine(a, b):
            dot = sum(x*y for x, y in zip(a, b))
            na = math.sqrt(sum(x*x for x in a))
            nb = math.sqrt(sum(y*y for y in b))
            return dot / (na * nb + 1e-10)
        docs = list(docs)[:20]
        D = [emb.embed_query(getattr(d, 'page_content', str(d))[:2000]) for d in docs]
        sims = [cosine(q, d) for d in D]
        # Selecci√≥n MMR 5 docs
        selected_idx = []
        if sims:
            first = max(range(len(docs)), key=lambda i: sims[i])
            selected_idx.append(first)
            while len(selected_idx) < min(5, len(docs)):
                best_i = None; best_score = -1e9
                for i in range(len(docs)):
                    if i in selected_idx:
                        continue
                    max_sim_to_S = max(cosine(D[i], D[j]) for j in selected_idx) if selected_idx else 0.0
                    score = 0.5 * sims[i] - 0.5 * max_sim_to_S
                    if score > best_score:
                        best_score = score; best_i = i
                if best_i is None:
                    break
                selected_idx.append(best_i)
        for i, d in enumerate(docs):
            results.append({
                "score": round(sims[i], 6) if i < len(sims) else 0.0,
                "selected": i in selected_idx,
                "text_preview": getattr(d, 'page_content', str(d))[:500]
            })
        return results
    except Exception as e:
        logging.error(f"Error in get_docs_with_scores: {e}")
        return results
